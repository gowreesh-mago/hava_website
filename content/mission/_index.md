---
title: "Mission & Research"
description: "HAVA-Lab focuses on human-aligned video-AI, shifting from raw accuracy to alignment with human values, legal norms, and societal acceptance."
---



## Our Solution: Three Research Objectives

HAVA-Lab enables human-aligned video-AI by addressing three interconnected research objectives that form a continuous feedback loop: developing new alignment drives algorithmic development, and algorithmic development sheds new light on where alignment is most needed.

---

## Research Objective 1: Human Alignment in Video-AI

The goal is to incorporate human-alignment during the development lifetime of video-AI algorithms from cognitive, ethical, and legal perspectives, each led by a PhD student.

### Cognitive Alignment

Can video-AI become more computationally efficient by making it resemble the human brain? The rich perceptual content of video, with objects moving and activities unfolding in space-time, poses a much more challenging cognitive-alignment problem than work focusing on static images only. We expect dynamic adaptation and sparser network geometries to better approximate human efficiency.

*Led by Dr. Iris Groen (FNWI)*

### Ethical Alignment

How to embed ethical values better in video-AI algorithms? Based on the method of Jaton, we systematically record moments of 'hesitation' in the production of video-AI models to understand where genuine choices in the sense of pragmatic morality lie, how to represent these genuine choices in the video-AI algorithms, and how to develop new standards for labeling that include these choices.

*Led by Prof. dr. Tobias Blanke (FGw)*

### Legal Alignment

This project considers video-AI compliance with fundamental rights and ethical values our European societies are based on. Can we incorporate privacy and legal standards of non-maleficence, equity, or justice by design? Can we develop human-aligned video-AI that accords with legal and regulatory concerns, while grounding legal and policy discussions in technical realities?

*Led by Dr. mr. Heleen Janssen (FdR)*

---

## Research Objective 2: Human-Aligned Video-AI for UvA

The goal is to develop video-AI with desired human alignment embedded and usable for the non-expert. We focus on four novel use cases directly relevant for research and education at UvA.

### Criminal Behavior

Video-AI has the potential to detect crime from camera recordings and provide insights into crime-types that are currently unregistered and unreported. However, specialist insights are still required to deal with human biases present in existing data. This requires developing insights into what can be used for detection and new video-AI algorithms recognizing crime without perpetuating unwanted biases.

*Led by Prof. dr. Marie Lindegaard (FMG)*

### Skill Assessment

How can video-AI become more robust and safeguarded against annotation biases when it comes to real-world deployment, especially in medical settings when assessing skills? And how should video-AI algorithms be developed to be ethically sound in production when trained under skillslab conditions? We investigate the step from lab to real world for video-AI constrained by ethical constraints on fairness across all relevant dimensions.

*Led by Prof. dr. Marlies Schijven (AUMC)*

### Diagnostic Training

Diagnostic training is a critical aspect of dental education, as students often struggle with interpreting radiographs. To improve the quality and efficiency of diagnostic training, video-AI can play a crucial role. We research video-AI algorithms to compare learning strategies and provide insight into diagnostic failures by recognizing the student's behavior and gaze patterns during diagnostic assessment, creating more proficient future dentists.

*Led by Dr. Erwin Berkhout (ACTA)*

### Responsible Marketing

A central theme in social media analysis is organized online campaigns, both political and economical. In such content, text and image recognition is common, yet videos are often ignored while being key when it comes to virality or synchronized campaigning. We investigate the role of videos in such social content and the development of video-AI algorithms for detecting when video content has viral potential through domain-specific guidance and alignment.

*Led by Dr. Stevan Rudinac (FEE)*

---

## Research Objective 3: Democratize Human-Aligned Video-AI

Knowledge transfer of human-aligned video-AI happens at the DSC. We organize:

- A monthly **HAVA-Faculty-focus** where the research of one student is highlighted together with an invited speaker
- Twice yearly **HAVA-workshops** with tutorials and hands-on notebooks to share human-aligned video-AI methodologies and practices
- A yearly **HAVA-conference** to share our research and have round table discussions with the broad UvA community interested in human-aligned video-AI

---

## Outcomes

The lab will culminate its outcomes into a virtual dashboard, where key findings are visualized, summarized in blogpost-style, and with technical advances handed out as easy-to-use notebooks. The dashboard will include video demonstrators showcasing qualitative outputs of research and visual summaries of proposed human alignment along the cognitive, ethical, and legal axes, as well as published research presented in short explainer videos made publicly available.

Besides publications and PhD theses, we expect to deliver the software and data that are part of each project.

Publications aim for technical-AI venues like CVPR and NeurIPS, multi-disciplinary venues like ACM Multimedia and ACM FAccT, as well as discipline-specific venues relevant for each project.
